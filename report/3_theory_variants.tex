\chapter{Arbitrage-free calibration and MOT problem}
\section{Arbitrage constraints}






\section{CMS forward joint calibration problem}

\begin{comment}
    \chapter{Theoretical analysis and methodology }
\section{Problem Formulation}
	Let's familiarize ourselves with some fundamental notions related to an American option with maturity $T>0$, which can be exercised at any time $t \in (0,T]$. For this purpose, we consider a filtered probability space denoted by $(\Omega,\mathcal{F},\mathbb{F},\mathbb{Q}^{T_{n}})$, where $\mathbb{F}$ represents the augmented filtration of a d-dimensional Brownian motion $(W_{t})_{t\in [0,T]}$, and $\mathbb{Q}$ denotes the risk-neutral probability measure while $\mathbb{Q}^{T_{n}}$ used to represent the forward measure. Furthermore, we introduce $(\beta_{t})_{t}$, which signifies the value of a risk-free account at time $t$. Typically, this value corresponds to that of bank deposits, while in the context of interest rate products, it equates to the value of zero-coupon bonds. Additionally, we utilize $(X_{t})_{t}$ to denote the underlying process or the diffusion process, particularly relevant in the interest rate product scenario. Moreover, we define $(Z_{t})_{t}$ as the $\mathbb{F}$-adapted, right-continuous payoff process of the option, satisfying condition $\mathbb{E}[\sup_{t\in[0,T]}Z_{t}] < \infty$.
	
	Introducing $\tau$ as a stopping time and $\mathcal{T}$ as the set of all stopping times with respect to the filtration $\mathbb{F}$, we can express the value of the American option at time $t$ as shown in equation $$V_{t} = \text{ess sup}_{\tau \in \mathcal{T},\tau \geq t}\mathbb{E}[\beta_{t}\frac{Z_{\tau}}{\beta_{\tau}}|\mathcal{F}_{t}].$$ Notably, the price of the American option corresponds to its value at initial time $t_{0}$, as shown in equation $$V_{0}=\sup_{\tau \in \mathcal{T}}\beta_{0}\mathbb{E}[\frac{Z_{\tau}}{\beta_{\tau}}]\quad \text{(Primal Form)}.$$
	
	\subsection{Lower bound of the option price}
	The primal form of the pricing problem reveals a significant dependency of the theoretical or optimal price of the American option on the chosen stopping strategy. For any particular designed stopping strategy denoted by $\hat{\tau}$, the resulting value is $$\hat{V_{0}}=\beta_{0}\mathbb{E}[\frac{Z_{\hat{\tau}}}{\beta_{\hat{\tau}}}] \leq \sup_{\tau \in \mathcal{T}}\beta_{0}\mathbb{E}[\frac{Z_{\tau}}{\beta_{\tau}}] = V_{0}^{\text{theoretical}}.$$ We can interpret this formula as that the price obtained through a specific stopping strategy serves as a conservative estimate, which will always be either less than or at most equal to the theoretical price. This intuitive observation leads us to the idea that the estimation of the American option price, based on any specific strategy, represents a lower bound of its theoretical value. 

	
	\subsection{Upper bound of the option price}
	Regarding the upper bounds, it is important to note that the discounted option value process $(\frac{V_{t}}{\beta_{t}})_{t\in[0,T]}$ is a supermartingale of class $D$, thereby possessing a unique Doob-Meyer decomposition as shown following $$(\frac{V_{t}}{\beta_{t}})_{t\in[0,T]} = V_{0}^{\text{theoretical}}+M_{t}^{*}-A_{t}^{*},$$ where $M_{t}^{*} \in \mathcal{M}^{UI}$ the set of all uniformly integrable martingales with initial state $0$, and $A_{t}^{*}$ is a predictable increasing process with initial state $0$. 
	
	Rogers \cite{rogers2002monte} has demonstrated the dual form of the American option price, represented as follows $$V_{0}^{\text{theoretical}} = \inf _{M \in \mathcal{M}^{UI}} \beta_{0} \mathbb{E}[\sup_{t \in [0,T]}\frac{Z_{t}}{\beta_{t}}-M_{t}].$$ Furthermore, Rogers' work \cite{rogers2002monte} has revealed that the infimum of this dual formulation is attained when the martingale $M$ is chosen as $M^{*}$ in the Doob-Meyer decomposition.
	
	By using the martingale representation theorem, we can characterize this optimal martingale $M^{*}$. Specifically, there exists a predictable process $\Psi \in \mathbb{H}^{2}$ such that, $$M^{*}=M_{0}^{*}+\int_{0}^{t}\Psi_{s}dW_{s}.$$ By following this approach, we gain insight into the estimation of the optimal martingale $M^{*}$ by numerically approximating the process $\Psi$ and its stochastic integral. Consequently, this enables us to generate a robust upper bound for the option price. This method proves to be valuable for obtaining a reliable upper estimate of the American option price with small differences.
	
	\section{Numerical valuation of American options}
	%some text\cite{citation-2-name-here}, some more text
	The American option grants holders the privilege to exercise their rights at any point in time. However, when conducting computer simulations, we are constrained to working with discrete time intervals. In light of this, a pragmatic approach emerges: the approximation of American options through the utilization of Bermudan options, characterized by exercise times confined to a discrete set  $t_{i} = i Â· \Delta t$, where $i$ takes values from the set $\{1, ..., n\}$, and $\Delta t$ is defined as $\frac{T}{n}$. 
	\subsection{Rewrite the problem}
	The discretized time set offers a notable advantage: the ability to calculate conditional expectations at these specific time instances. By computing the expected value of the discounted option value, conditioned on the filtration $\mathcal{F}_{t_{i}}$ and combining the Doob-Meyer decomposition with the martingale representation, we arrive once again,
    \begin{equation}\label{eq1}
      \frac{V_{t_{i+1}}}{\beta_{t_{i+1}}} = \mathbb{E}[\frac{V_{t_{i+1}}}{\beta_{t_{i+1}}}|\mathcal{F}_{t_{i}}]+\int_{t_{i}}^{t_{i+1}}\Psi_{u}dW_{u}   
    \end{equation}
    Upon multiplication of both sides by multiple $\beta_{t_{i}}$, the formula \ref{eq1} takes the subsequent form: 
    \begin{equation}\label{eq2}
        \beta_{t_{i}}\frac{V_{t_{i+1}}}{\beta_{t_{i+1}}} = \underbrace{\beta_{t_{i}}\mathbb{E}[\frac{V_{t_{i+1}}}{\beta_{t_{i+1}}}|\mathcal{F}_{t_{i}}]}_{\text{Continuation Value}\  \Phi_{t_{i}}}+\underbrace{\beta_{t_{i}}\int_{t_{i}}^{t_{i+1}}\Psi_{u}dW_{u}}_{\text{Martingale Increment}}.
    \end{equation}

    It's worth noting that the initial term on the right side signifies the Continuation Value $\Phi_{t_{i}}$. This signifies the anticipated value at time $t_{i}$ if the holder retains the option and defers their decision until the subsequent time point. Regarding the second term, it is denoted as the Martingale Increment.

    In their work \cite{mission}, the authors propose that when the underlying process $X_{t}$ have the Markovian property, both the conditional expectation $\Phi_{t}$ and the process $\Psi_{t}$ can be expressed in terms of the state variables $X_{t}$. This suggests a promising approach: we can model the functions representing the continuation value $\Phi_{t}$ and the state of the process $\Psi_{t}$ based on $X_{t}$. As a result, we can derive an estimated continuation value for any given value of $X_{t}$. However, when it comes to the martingale increment, it remains necessary to approximate the value of the stochastic integral.

    \subsection{Approximation of Martingale Increments}
	We introduce two discretization schemes for the stochastic integral
    \begin{equation}\label{int}
        \int_{t_{i}}^{t_{i+1}}\Psi_{u}dW_{u}.
    \end{equation}
    
    \subsubsection{Euler Scheme}
    The most simplest method for discretizing the process outlined in Equation \ref{int} is to apply Euler discretization. This approach is to approximate the integrals through the utilization of the left-point rule, given that the value of $\Psi(X_{t},t)$ is known at time $t$. Consequently, the integral is approximated as the multiplication of the integrand at time t by the integration increment $dt$
    \begin{align*}
    \int_{t_{i}}^{t_{i+1}}\Psi(X_{u},u)dW_{u} &\approx \Psi(X_{t_{i}},t_{i})\int_{t_{i}}^{t_{i+1}}dW_{u}\\
    &= \Psi(X_{t_{i}},t_{i})(W_{t_{i+1}}-W_{t_{i}})\\
    &= \Psi(X_{t_{i}},t_{i})\Delta W_{t_{i}}.
    \end{align*}
    \subsubsection{Milstein Scheme}
    This scheme is described in Glasserman \cite{glasserman2004monte} for general processes.
    Assume the dynamic of the state (underlying) process is:
        $$dX_{t}=f(t,X_{t})dt+\sigma(t,X_{t})dW_{t}.$$
        By Ito's formula,
        $$d\Psi(X_{t}) = (\Psi^{'}(X_{t})f+\frac{1}{2}\Psi^{''}(X_{t})\sigma^{2})dt + \sigma \Psi^{'}(X_{t}) dW_{t}.$$
        Then expand the process $\Psi$ as :
        $$\Psi_{u} = \Psi_{t}+\int_{t}^{u}(\Psi^{'}(X_{t})f+\frac{1}{2}\Psi^{''}(X_{t})\sigma^{2})ds + \int_{t}^{u}\sigma \Psi^{'}(X_{s}) dW_{s}.$$
        So for the integral,
        \begin{align*}\label{milstein}
        \int_{t_{i}}^{t_{i+1}}\Psi_{u}dW_{u} &= \int_{t_{i}}^{t_{i+1}}\Psi_{t_{i}}dW_{u}+\int_{t_{i}}^{t_{i+1}}\int_{t_{i}}^{u}\sigma \Psi^{'}(X_{s}) dW_{s}dW_{u} \\ 
        &\quad + \mathcal{O}((dt)^{2})+\mathcal{O}((dt)^{3/2})\\
        &\approx \Psi(X_{t_{i}})\Delta W_{t_{i}} + \sigma \Psi^{'}(X_{t_{i}})\int_{t_{i}}^{t_{i+1}}\int_{t_{i}}^{u}dW_{s}dW_{u}\\
        &= \Psi(X_{t_{i}})\Delta W_{t_{i}} + \sigma \Psi^{'}(X_{t_{i}})(\frac{\Delta W_{t_{i}}^{2}-\Delta t}{2}),
        \end{align*}
    where $\Delta W_{t_{i}} = W_{t_{i+1}} - W_{t_{i}}$.
    As demonstrated in the forthcoming sections, it is evident that the Milstein Scheme significantly outperforms the Euler Scheme. As a result, in the following theoretical part, we consistently employ the Milstein Scheme to approximate the Martingale Increment term. 
    
    \subsection{Core formula}
    When we bring together equation \ref{eq2} and the Milstein Scheme, we obtain the fundamental equation shown below,
    \begin{equation*} \label{key}
         \beta_{t_{i}}\frac{V_{t_{i+1}}}{\beta_{t_{i+1}}} \approx 
        \Phi_{t_{i}}(X_{t_{i}})+
        \beta_{t_{i}}(\Psi_{t_{i}}(X_{t_{i}})\Delta W_{t_{i}} + \sigma \Psi^{'}_{t_{i}}(X_{t_{i}})(\frac{\Delta W_{t_{i}}^{2}-\Delta t}{2})) \quad (*)
    \end{equation*}
      This equation serves as the core formula. In the upcoming sections, it will serve both as a foundation for loss functions in the training of neural networks and as a reference for updating upper and lower bounds.

\section{Algorithm}
Based on the theoretical analysis presented above, now we introduce the algorithm which generate simutaneously the upper and lower bounds of the Bermudan option price.

Let's revisit the notation: $Z(X_{t}): \mathbb{R}^{d} \rightarrow \mathbb{R}$ represents the payoff process of the option at time $t \in (0,T]$. We assume that $\Phi(X_{t_{i}}): \mathbb{R}^{d} \rightarrow \mathbb{R}$ and $\Psi(X_{t_{i}}): \mathbb{R}^{d} \rightarrow \mathbb{R}$ serve as approximated functions for the continuation value and the predicted process at time $t_{i}$, respectively. The martingale increment can be estimated using 
$$\Psi(X_{t_{i}})\Delta W_{t_{i}} + \sigma \Psi^{'}(X_{t_{i}})(\frac{\Delta W_{t_{i}}^{2}-\Delta t}{2}).$$

Now, consider two stochastic processes $(L_{t_{i}})_{i=1}^{n}, (U_{t_{i}})_{i=1}^{n}$. These processes will be iteratively updated in a backward manner, and their expectations will be a lower and an upper bound for the option price respectively. The updating procedure is presented as follows.

\subsection{Generate lower and upper bounds}
\subsubsection{Lower bounds}
To generate a lower bound, recall that for any specific stopping strategy, the result is less than the optimal. Here, we choose the strategy:	
at each time step $t_{0} < t_{i} < t_{n}$, the option holder either exercises the option immediately
if the payoff value is higher than the continuation value, or waits until the next exercise point if it is lower, i.e. at $t_{i}$, the correspond stopping time is,
$$\tau_{i}=\min\{t_{j} \in \{t_{i},t_{i+1},..., t_{n+1}\}:Z(X_{t_{j}})\geq \Phi(X_{t_{j}})\}.$$
\begin{itemize}
    \item At $t_{n}=T$, the option holder faces a decision: either exercise the option if it's profitable (in the money), or allow it to expire if it's not profitable (out of the money). Consequently, we have $ L_{t_{n}} = \max(Z(X_{t_{n}}),0)$
    \item At other time steps, we follows the stopping strategy, so, at $t_{n-1}:$ 
     $$L_{t_{n-1}} =
    \begin{cases}
        Z(X_{t_{n-1}}), \quad \text{if } Z(X_{t_{n-1}}) \geq \Phi_{t_{n-1}}(X_{t_{n-1}}) \\
        \\
        \Phi_{t_{n-1}}(X_{t_{n-1}}), \ \text{Otherwise}
    \end{cases}$$
    But in the second case, instead of using directly the value output by function $\Phi_{t_{n-1}}$, we using its equivalent part in core formula
    $$\frac{\beta_{t_{n-1}}L_{t_{n}}}{\beta_{t_{n}}}-  \beta_{t_{n-1}}(\Psi_{t_{n-1}}(X_{t_{n-1}})\Delta W_{t_{n-1}} +\sigma \Psi_{t_{n-1}}^{'}(X_{t_{n-1}})(\frac{\Delta W_{t_{n-1}}^{2}-\Delta t}{2})),$$ beacause theoretically, the expectation of the martingale increment is zero, in this way, by applying the idea of control variate, we reduce the variance of the estimated option prices.
   
     ...
    \item Until the initial step $t_{0}$, it is a little trival. As the holder don't exercise the option at initial, we proceed to update the prices without requiring any comparisons
    $$
    L_{t_{0}} = \frac{\beta_{t_{0}}L_{t_{1}}}{\beta_{t_{1}}}-  \beta_{t_{0}}(\Psi_{t_{0}}(X_{t_{0}})\Delta W_{t_{0}} +\sigma \Psi_{t_{0}}^{'}(X_{t_{0}})(\frac{\Delta W_{t_{0}}^{2}-\Delta t}{2})).
    $$
\end{itemize}

\subsubsection{Upper bounds}
As for generating the upper bound $(U_{t_{i}})_{i=1}^{n}$, by using the dual formulation of the option price 
$$V_{0}^{optimal} = \inf _{M \in \mathcal{M}^{UI}} \beta_{0} \mathbb{E}[\sup_{t \in [0,T]}(\frac{Z_{t}}{\beta_{t}}-M_{t})],$$
so we obtain the upper bounds at each step through
$$U_{t_{i}} = \beta_{t_{i}}\mathbb{E}[\sup_{\tau \geq t_{i}}(\frac{Z_{\tau}}{\beta_{\tau}}-M_{\tau})|\mathcal{F}_{t_{i}}],$$ where $M_{t}$ is the martingale $\int_{0}^{t}\Psi_{u}dW_{u}$.

\begin{itemize}
    \item At $t_{n}=T$: the same as $L_{t_{n}}$, the holder whether exercise the option or let it expire, $U_{t_{n}} = \max(Z(X_{t_{n}}),0)$
    
    ...
    
    \item At $t_{i}$: in this context, we observe two details regarding the upper bound formula. The first observation is that it's unnecessary to compare the values across all steps after $t_{i}$. Since we construct $(U_{t_{i}})_{i=1}^{n}$ in a backward manner, the knowledge of the maximum value beyond $t_{i+1}$ is already contained within $U_{t_{i+1}}$. As a result, we only need to compare the values between $t_{i}$ and $t_{i+1}$. The second is that since we take the conditional expectation on $\mathcal{F}_{t_{i}}$, the only remaining martingale term solely concerns the martingale increment between these two steps, so we have,
        \begin{align*}
            U_{t_{i}} = \max(Z(X_{t_{i}}),\frac{\beta_{t_{i}}U_{t_{i+1}}}{\beta_{t_{i+1}}}-  \beta_{t_{i}}&(\Psi_{t_{i}}(X_{t_{i}})\Delta W_{t_{i}} + \sigma \Psi_{t_{i}}^{'}(X_{t_{i}})(\frac{\Delta W_{t_{i}}^{2}-\Delta t}{2})))
        \end{align*}
    ...

    \item until $t_{0}$, similarly, we update the upper bound directly,
    $$
    U_{t_{0}} = \frac{\beta_{t_{0}}U_{t_{1}}}{\beta_{t_{1}}}-  \beta_{t_{0}}(\Psi_{t_{0}}(X_{t_{0}})\Delta W_{t_{0}} +\sigma \Psi_{t_{0}}^{'}(X_{t_{0}})(\frac{\Delta W_{t_{0}}^{2}-\Delta t}{2})).
    $$
\end{itemize}

\subsection{Training Neural Networks}
To approximate the functions for continuation value $(\Phi_{t_{i}})_{i=1}^{n}$ and the predictable process $(\Psi_{t_{i}})_{i=1}^{n}$, for each respective step, we employ fully-connected feedforward neural networks to perform regression, guided by equation $(*)$, which means we use equation $(*)$ to define the loss function in training process.

\begin{figure}[!h]
\centering
\includegraphics[scale=0.8]{images/role.png} 
\caption{The role of neural networks}
\label{role} 
\end{figure}

Numerous choices exist when it comes to designing the structure of the neural network and selecting appropriate training hyperparameters. In the subsequent sections, we will provide detailed explanations using specific examples to elucidate these aspects.

In summary, considering the information discussed above, we present the algorithm as follows,
\begin{algorithm}
  \small \KwData{Simulate $N$ stock paths}
  \small Initialise $U_{t_{n}} = L_{t_{n}} = Z(X_{t_{n}})$\\
  \For{i=n-1:1 \do}{
  \small Regress $\frac{\beta_{t_{i}}L_{t_{i+1}}}{\beta_{t_{i}}}$ on $X_{t_{i}}:$\\
  \quad \quad \small $\min_{\Phi_{t_{i}},\Psi_{t_{i}}}\mathcal{L}(\Psi_{t_{i}}(X_{t_{i}}),\Phi_{t_{i}}(X_{t_{i}}),L_{t_{i+1}}\frac{\beta_{t_{i}}}{\beta_{t_{i+1}}},\Delta W_{t_{i}}).$
  \small $L_{t_{i}} = \frac{\beta_{t_{i}}L_{t_{i+1}}}{\beta_{t_{i+1}}}-  \beta_{t_{i}}(\Psi_{t_{i}}(X_{t_{i}})\Delta W_{t_{i}} +\sigma \Psi_{t_{i}}^{'}(X_{t_{i}})(\frac{\Delta W_{t_{i}}^{2}-\Delta t}{2}))$
  \small $U_{t_{i}} = \frac{\beta_{t_{i}}U_{t_{i+1}}}{\beta_{t_{i+1}}}-  \beta_{t_{i}}(\Psi_{t_{i}}(X_{t_{i}})\Delta W_{t_{i}} +\sigma \Psi_{t_{i}}^{'}(X_{t_{i}})(\frac{\Delta W_{t_{i}}^{2}-\Delta t}{2}))$
  
  \If{$Z(X_{t_{i}})>\Phi_{t_{i}}(X_{t_{i}})$}
    {
        $L_{t_{i}} = Z(X_{t_{i}})$
    }
  \If{$Z(X_{t_{i}}) > U_{t_{i}}$}
    {
        $U_{t_{i}} = Z(X_{t_{i}})$
    }
}
\small Regress $\frac{\beta_{t_{0}}L_{t_{1}}}{\beta_{t_{0}}}$ on $X_{t_{0}}$:
\small $\min_{\Phi_{t_{0}},\Psi_{t_{0}}}\mathcal{L}(\Psi_{t_{0}}(X_{t_{0}}),\Phi_{t_{0}}(X_{t_{0}}),L_{t_{1}}\frac{\beta_{t_{0}}}{\beta_{t_{1}}},\Delta W_{t_{0}}).$
\small $L_{t_{0}} = \frac{\beta_{t_{0}}L_{t_{1}}}{\beta_{t_{1}}}-  \beta_{t_{0}}(\Psi_{t_{0}}(X_{t_{0}})\Delta W_{t_{0}} +\sigma \Psi_{t_{0}}^{'}(X_{t_{0}})(\frac{\Delta W_{t_{0}}^{2}-\Delta t}{2}))$
\small $U_{t_{0}} = \frac{\beta_{t_{0}}U_{t_{1}}}{\beta_{t_{1}}}-  \beta_{t_{0}}(\Psi_{t_{0}}(X_{t_{0}})\Delta W_{t_{0}} +\sigma \Psi_{t_{0}}^{'}(X_{t_{0}})(\frac{\Delta W_{t_{0}}^{2}-\Delta t}{2}))$
\caption{American Option Pricing with Multiple Neural Networks}
\end{algorithm}
where the loss function $\mathcal{L}$ deduced from equation $(*)$,
\footnotesize
$$
   \mathcal{L}(\Psi_{t_{i}},\Phi_{t_{i}},L_{t_{i+1}}\frac{\beta_{t_{i}}}{\beta_{t_{i+1}}},\Delta W_{t_{i}})=\small (\beta_{t_{i}}\frac{L_{t_{i+1}}}{\beta_{t_{i+1}}} -
			\Phi_{t_{i}}(X_{t_{i}})-
			\beta_{t_{i}}(\Psi_{t_{i}}(X_{t_{i}})\Delta W_{t_{i}} + \sigma \Psi^{'}_{t_{i}}(X_{t_{i}})(\frac{\Delta W_{t_{i}}^{2}-\Delta t}{2})))^{2}.
$$
\end{comment}
